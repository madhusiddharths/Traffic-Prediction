{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:07.240889Z",
     "start_time": "2025-06-04T21:46:06.957418Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import joblib\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "import requests\n",
    "import heapq\n",
    "import folium\n",
    "from geopy.geocoders import Nominatim\n",
    "from bs4 import BeautifulSoup"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjoblib\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PolynomialFeatures\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrequests\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/__init__.py:87\u001B[0m\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001B[39;00m\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;66;03m# process, as it may not be compiled yet\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     81\u001B[0m     \u001B[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001B[39;00m\n\u001B[1;32m     82\u001B[0m     \u001B[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001B[39;00m\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     84\u001B[0m         __check_build,  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[1;32m     85\u001B[0m         _distributor_init,  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[1;32m     86\u001B[0m     )\n\u001B[0;32m---> 87\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m clone\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_show_versions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m show_versions\n\u001B[1;32m     90\u001B[0m     __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     91\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcalibration\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     92\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcluster\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    133\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshow_versions\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    134\u001B[0m     ]\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:19\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_config\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config_context, get_config\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexceptions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m InconsistentVersionWarning\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _IS_32BIT\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_estimator_html_repr\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_metadata_requests\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _MetadataRequester, _routing_enabled\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/__init__.py:28\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdiscovery\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m all_estimators\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfixes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parse_version, threadpool_info\n\u001B[0;32m---> 28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmurmurhash\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m murmurhash3_32\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvalidation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     30\u001B[0m     _is_arraylike_not_scalar,\n\u001B[1;32m     31\u001B[0m     _is_pandas_df,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     43\u001B[0m     indexable,\n\u001B[1;32m     44\u001B[0m )\n\u001B[1;32m     46\u001B[0m \u001B[38;5;66;03m# Do not deprecate parallel_backend and register_parallel_backend as they are\u001B[39;00m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;66;03m# needed to tune `scikit-learn` behavior and have different effect if called\u001B[39;00m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;66;03m# from the vendored version or or the site-package version. The other are\u001B[39;00m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;66;03m# utilities that are independent of scikit-learn so they are not part of\u001B[39;00m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;66;03m# scikit-learn public API.\u001B[39;00m\n",
      "File \u001B[0;32msklearn/utils/murmurhash.pyx:1\u001B[0m, in \u001B[0;36minit sklearn.utils.murmurhash\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-06-04T21:47:03.211356Z",
     "start_time": "2025-06-04T21:47:03.063778Z"
    }
   },
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.sort_values(['Sample Time'], inplace=True, ascending=True)\n",
    "df.head()"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      2\u001B[0m df\u001B[38;5;241m.\u001B[39msort_values([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSample Time\u001B[39m\u001B[38;5;124m'\u001B[39m], inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, ascending\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      3\u001B[0m df\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_engine(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m get_handle(\n\u001B[1;32m   1881\u001B[0m     f,\n\u001B[1;32m   1882\u001B[0m     mode,\n\u001B[1;32m   1883\u001B[0m     encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1884\u001B[0m     compression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompression\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1885\u001B[0m     memory_map\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmemory_map\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[1;32m   1886\u001B[0m     is_text\u001B[38;5;241m=\u001B[39mis_text,\n\u001B[1;32m   1887\u001B[0m     errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding_errors\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1888\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstorage_options\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1889\u001B[0m )\n\u001B[1;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1891\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[1;32m    874\u001B[0m             handle,\n\u001B[1;32m    875\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[1;32m    876\u001B[0m             encoding\u001B[38;5;241m=\u001B[39mioargs\u001B[38;5;241m.\u001B[39mencoding,\n\u001B[1;32m    877\u001B[0m             errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[1;32m    878\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    879\u001B[0m         )\n\u001B[1;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data.csv'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:56.474491Z",
     "start_time": "2025-06-04T21:46:56.465839Z"
    }
   },
   "source": [
    "def get_input():\n",
    "    time = pd.to_datetime(\"04-26-2024 16:35:00\")\n",
    "    print(\"time : \", time)\n",
    "    day_of_week = time.weekday()+1\n",
    "    print(\"day of week : \", day_of_week)\n",
    "    input_array = np.zeros(43)\n",
    "    print(\"input array : \", input_array)\n",
    "    input_array[day_of_week - 1] = 1\n",
    "    hour = time.hour\n",
    "    input_array[6 + hour - 1] = 1\n",
    "    minute = time.minute\n",
    "    minute = round(minute / 5) * 5\n",
    "    input_array[31 + round(minute / 5)] = 1\n",
    "    print(\"updated input array : \", input_array)\n",
    "    return input_array\n",
    "input_array = get_input()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time :  2024-04-26 16:35:00\n",
      "day of week :  5\n",
      "input array :  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "updated input array :  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:57.817195Z",
     "start_time": "2025-06-04T21:46:57.799704Z"
    }
   },
   "source": [
    "def transform_input(input_array):\n",
    "    train_features = df.drop(['Sample Time','total', '1212480 Lane 1 Flow','1212480 Lane 2 Flow','1212480 Lane 3 Flow','day_of_week','hour','minute'], axis = 1)\n",
    "    poly = PolynomialFeatures(2)\n",
    "    train_label = df['total']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train_features, train_label, test_size=0.1, random_state=1, shuffle=True)\n",
    "    poly.fit(x_train)\n",
    "    transformed_array = poly.transform(input_array.reshape(1,43))\n",
    "    print(\"transformed : \", transformed_array)\n",
    "    return transformed_array\n",
    "transformed_array = transform_input(input_array)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransformed : \u001B[39m\u001B[38;5;124m\"\u001B[39m, transformed_array)\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m transformed_array\n\u001B[0;32m---> 10\u001B[0m transformed_array \u001B[38;5;241m=\u001B[39m transform_input(input_array)\n",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m, in \u001B[0;36mtransform_input\u001B[0;34m(input_array)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform_input\u001B[39m(input_array):\n\u001B[0;32m----> 2\u001B[0m     train_features \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mdrop([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSample Time\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtotal\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1212480 Lane 1 Flow\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1212480 Lane 2 Flow\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1212480 Lane 3 Flow\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mday_of_week\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhour\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mminute\u001B[39m\u001B[38;5;124m'\u001B[39m], axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      3\u001B[0m     poly \u001B[38;5;241m=\u001B[39m PolynomialFeatures(\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m      4\u001B[0m     train_label \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtotal\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:07.256656Z",
     "start_time": "2024-04-25T16:11:54.814764900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction :  [225.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MADHU SIDDHARTH S\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def make_predictions(transformed_array):\n",
    "    with open('rf.pkl', 'rb') as file:\n",
    "        model = joblib.load(file)\n",
    "    prediction = model.predict(transformed_array.reshape(1,43))\n",
    "    return prediction\n",
    "prediction = make_predictions(input_array).round()\n",
    "print(\"prediction : \", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:08.352908Z",
     "start_time": "2025-06-04T21:46:08.332180Z"
    }
   },
   "source": [
    "def newsapi():\n",
    "    url = ('https://newsapi.org/v2/everything?'\n",
    "           'q=california&'\n",
    "           'in=San Francisco&'  # Corrected the typo in 'Los angels' to 'Los Angeles'\n",
    "           'from=2024-04-20T00:00:01Z&'\n",
    "           'to=2024-04-24T23:59:59Z&'\n",
    "           'apiKey=f9c8762980744e5b9660c8b43090af2d')\n",
    "    response = requests.get(url)\n",
    "    articles = []\n",
    "    for article in response.json()['articles']:\n",
    "        description = article.get('description', '')  # Get the description or an empty string if not present\n",
    "        if description is not None and any(keyword in description.lower() for keyword in ['accident', 'protest', 'lane close']):\n",
    "            print(description)\n",
    "            articles.append(description)\n",
    "    if len(articles) == 0:\n",
    "        print(\"No news found\")\n",
    "    return articles\n",
    "articles = newsapi()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 18\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo news found\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m articles\n\u001B[0;32m---> 18\u001B[0m articles \u001B[38;5;241m=\u001B[39m newsapi()\n",
      "Cell \u001B[0;32mIn[2], line 8\u001B[0m, in \u001B[0;36mnewsapi\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnewsapi\u001B[39m():\n\u001B[1;32m      2\u001B[0m     url \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://newsapi.org/v2/everything?\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      3\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mq=california&\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      4\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124min=San Francisco&\u001B[39m\u001B[38;5;124m'\u001B[39m  \u001B[38;5;66;03m# Corrected the typo in 'Los angels' to 'Los Angeles'\u001B[39;00m\n\u001B[1;32m      5\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfrom=2024-04-20T00:00:01Z&\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      6\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mto=2024-04-24T23:59:59Z&\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      7\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mapiKey=f9c8762980744e5b9660c8b43090af2d\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 8\u001B[0m     response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mget(url)\n\u001B[1;32m      9\u001B[0m     articles \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m article \u001B[38;5;129;01min\u001B[39;00m response\u001B[38;5;241m.\u001B[39mjson()[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124marticles\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n",
      "\u001B[0;31mNameError\u001B[0m: name 'requests' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:16.757841Z",
     "start_time": "2025-06-04T21:46:16.747452Z"
    }
   },
   "source": [
    "# webscraping\n",
    "url = \"https://www.sfchronicle.com/in-depth-projects/2024/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the elements containing the data you want to extract\n",
    "    web_data = soup.find_all('div', class_='f fdc mx20 sm:mx32 xl:mxa sy20 mb40 xl:mw1200px')\n",
    "\n",
    "    # Check if any data was found\n",
    "    if web_data:\n",
    "        # Process the data\n",
    "        for data in web_data:\n",
    "            # Extract and print the text content of each element\n",
    "            print(data.text.strip())\n",
    "    else:\n",
    "        print(\"No data found on the webpage.\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage.\")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# webscraping\u001B[39;00m\n\u001B[1;32m      2\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://www.sfchronicle.com/in-depth-projects/2024/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 3\u001B[0m response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mget(url)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Check if the request was successful\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m200\u001B[39m:\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;66;03m# Parse the HTML content\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'requests' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:02:59.629382800Z",
     "start_time": "2024-04-25T17:02:59.628876Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def dijkstra(graph, start, end):\n",
    "    # Initialize distances dictionary with infinity for all nodes except start node\n",
    "    distances = {node: float('inf') for node in graph}\n",
    "    distances[start] = 0\n",
    "\n",
    "    # Priority queue to store nodes to visit\n",
    "    pq = [(0, start)]  # (distance, node)\n",
    "\n",
    "    # Dictionary to store the previous node in the shortest path\n",
    "    previous = {}\n",
    "\n",
    "    while pq:\n",
    "        current_distance, current_node = heapq.heappop(pq)\n",
    "\n",
    "        # Skip this iteration if the current distance to this node is not the shortest\n",
    "        if current_distance > distances[current_node]:\n",
    "            continue\n",
    "\n",
    "        # Explore neighbors of the current node\n",
    "        for neighbor, weight in graph[current_node].items():\n",
    "            distance = current_distance + weight\n",
    "            # If this path is shorter than previously known, update distance and previous node\n",
    "            if distance < distances[neighbor]:\n",
    "                distances[neighbor] = distance\n",
    "                previous[neighbor] = current_node\n",
    "                heapq.heappush(pq, (distance, neighbor))\n",
    "\n",
    "    # If the end node is not reachable\n",
    "    if end not in previous:\n",
    "        return None\n",
    "\n",
    "    # Reconstruct the shortest path\n",
    "    path = []\n",
    "    while end:\n",
    "        path.append(end)\n",
    "        end = previous.get(end)\n",
    "    return path[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:11:57.989081800Z",
     "start_time": "2024-04-25T16:11:57.913874800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_lat_long(building_name):\n",
    "    # Initialize Nominatim geocoder\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "\n",
    "    # Construct the address string with San Francisco\n",
    "    address = building_name + \", San Francisco\"\n",
    "\n",
    "    # Try to geocode the address\n",
    "    location = geolocator.geocode(address)\n",
    "\n",
    "    # If location found, return latitude and longitude\n",
    "    if location:\n",
    "        latitude = location.latitude\n",
    "        longitude = location.longitude\n",
    "        return latitude, longitude\n",
    "    else:\n",
    "        print(f\"Failed to geocode {building_name}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:11:58.005025800Z",
     "start_time": "2024-04-25T16:11:57.926246700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the Earth's surface using the Haversine formula.\n",
    "    \"\"\"\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    r = 6371  # Radius of Earth in kilometers\n",
    "    return r * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:11:58.005025800Z",
     "start_time": "2024-04-25T16:11:57.931205400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def distance(coordinates, latitude, longitude):\n",
    "    min_distance = float('inf')\n",
    "    key = None\n",
    "    for i in coordinates:\n",
    "        node_distance = haversine(latitude, longitude, coordinates[i][0], coordinates[i][1])\n",
    "        if node_distance < min_distance:\n",
    "            min_distance = node_distance\n",
    "            key = i\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:04:20.335987300Z",
     "start_time": "2024-04-25T17:04:20.323420800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_building(building):\n",
    "    buildings = {'hyatt' : [37.79429458516023, -122.3959216670412],\n",
    "             'federal reserve bank' : [37.79347115756132, -122.39606150557233],\n",
    "             'autodesk' : [37.79412348407684, -122.39515481057997],\n",
    "             'pacific gas' : [37.79161711991032, -122.39636233874825],\n",
    "             'beale street plaza' : [37.7917535627935, -122.39675995513431],\n",
    "             'on24' : [37.79132579462402, -122.39624571019917],\n",
    "             'park tower' : [37.79022928575979, -122.39454532915865],\n",
    "             'wizeline' : [37.791384271255936, -122.39533474022168],\n",
    "             'databricks' : [37.791099236856226, -122.39393059431788],\n",
    "             'ucf' : [37.79088164089771, -122.39216356320853],\n",
    "             'gap hq' : [37.7904862055847, -122.39062886805068],\n",
    "             'mira' : [37.79030128363038, -122.39136287056844],\n",
    "             'rincon apt' : [37.79164848037965, -122.3922755468832],\n",
    "             'lumina' : [37.78887712878227, -122.39239572459756],\n",
    "             'woodlands market' : [37.78913605029064, -122.3916839643332]}\n",
    "    return buildings[building]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:11:58.005025800Z",
     "start_time": "2024-04-25T16:11:57.968160300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "coordinates = {'I' : [37.792449682053594, -122.39743244631684],\n",
    "               'E' : [37.79314490019402, -122.39648830880148],\n",
    "               'A' : [37.7937926826253, -122.39565743493154],\n",
    "               'J' : [37.7911682686267, -122.39583260411536],\n",
    "               'F' : [37.79185283904245, -122.39494706864734],\n",
    "               'B' : [37.79254322386127, -122.3940707015303],\n",
    "               'K' : [37.7899323179828, -122.39428970500664],\n",
    "               'G' : [37.79061846867271, -122.39339682036328],\n",
    "               'C' : [37.791327201916516, -122.3925363386278],\n",
    "               'L' : [37.788706730073315, -122.3927653318488],\n",
    "               'H' : [37.78939758646449, -122.39186182842259],\n",
    "               'D' : [37.790169485406736, -122.3909632087987]}\n",
    "\n",
    "graph = {\n",
    "    'A': {'B': 1, 'E': 1},\n",
    "    'B': {'A': 1, 'C': 1, 'F': 1},\n",
    "    'C': {'B': 1, 'D': 1, 'G': 1},\n",
    "    'D': {'C': 1, 'H': 1},\n",
    "    'E': {'A': 1, 'F': 1, 'I': 1},\n",
    "    'F': {'B': 1, 'E': 1, 'G': 1, 'J': 1},\n",
    "    'G': {'C': 1, 'F': 1, 'H': 1, 'K': 1},\n",
    "    'H': {'D': 1, 'G': 1, 'L': 1},\n",
    "    'I': {'E': 1, 'J': 1},\n",
    "    'J': {'F': 1, 'I': 1, 'K': 1},\n",
    "    'K': {'G': 1, 'J': 1, 'L': 1},\n",
    "    'L': {'H': 1, 'K': 1}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:11:58.005025800Z",
     "start_time": "2024-04-25T16:11:57.968160300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# updating data gained from api and webscraping in graph edges\n",
    "# [vehicle, lane, road_blocks]\n",
    "traffic_information = {\n",
    "    'A': {'B': [140, 1, 1.0], 'E': [220, 2, 1.0]},\n",
    "    'B': {'A': [140, 1, 1.0], 'C': [130, 1, 1.0], 'F': [170, 2, 1.0]},\n",
    "    'C': {'B': [130, 1, 1.0], 'D': [135, 1, 1.0], 'G': [175, 2, 1.0]},\n",
    "    'D': {'C': [100, 1, 1.0], 'H': [110, 1, 1.0]},\n",
    "    'E': {'A': [230, 2, 1.0], 'F': [0, 0, 0], 'I': [230, 2, 1.0]},\n",
    "    'F': {'B': [110, 1, 1.0], 'E': [150, 2, 1.0], 'G': [0, 0, 0], 'J': [125, 1, 1.0]},\n",
    "    'G': {'C': [100, 1, 1.0], 'F': [235, 3, 1.0], 'H': [105, 1, 1.0], 'K': [145, 2, 1.0]},\n",
    "    'H': {'D': [95, 1, 1.0], 'G': [190, 2, 1.0], 'L': [95, 1, 1.0]},\n",
    "    'I': {'E': [240, 2, 1.0], 'J': [180, 3, 1.0]},\n",
    "    'J': {'F': [130, 1, 1.0], 'I': [0, 0, 0], 'K': [140, 2, 1.0]},\n",
    "    'K': {'G': [80, 1, 1.0], 'J': [85, 1, 1.0], 'L': [210, 3, 1.0]},\n",
    "    'L': {'H': [95, 1, 1.0], 'K': [0, 0, 0]}\n",
    "}\n",
    "\n",
    "market_street = ['A', 'E', 'I']\n",
    "mission_street = ['B', 'F', 'J']\n",
    "howard_street = ['C', 'G', 'K']\n",
    "folsom_street = ['D', 'H', 'L']\n",
    "\n",
    "spear_street = ['A', 'B', 'C', 'D']\n",
    "main_street = ['E', 'F', 'G', 'H']\n",
    "beale_street = ['I', 'J', 'K', 'L']\n",
    "\n",
    "for i in articles:\n",
    "    if \"market street\" in i:\n",
    "        for j in range(len(market_street)-1):\n",
    "            if traffic_information[j][j+1][1] != 0:\n",
    "                traffic_information[j][j+1][2] = 0.5\n",
    "        for j in range(len(market_street)-1, 0, -1):\n",
    "            if traffic_information[j][j-1][1] != 0:\n",
    "                traffic_information[j][j-1][2] = 0.5\n",
    "        print(\"updated market street\")\n",
    "\n",
    "    if \"mission street\" in i:\n",
    "        for j in range(len(mission_street)-1):\n",
    "            if traffic_information[j][j+1][1] != 0:\n",
    "                traffic_information[j][j+1][2] = 0.5\n",
    "        for j in range(len(mission_street)-1, 0, -1):\n",
    "            if traffic_information[j][j-1][1] != 0:\n",
    "                traffic_information[j][j-1][2] = 0.5\n",
    "        print(\"updated mission street\")\n",
    "\n",
    "    if \"howard street\" in i:\n",
    "        for j in range(len(howard_street)-1):\n",
    "            if traffic_information[j][j+1][1] != 0:\n",
    "                traffic_information[j][j+1][2] = 0.5\n",
    "        for j in range(len(howard_street)-1, 0, -1):\n",
    "            if traffic_information[j][j-1][1] != 0:\n",
    "                traffic_information[j][j-1][2] = 0.5\n",
    "        print(\"updated howard street\")\n",
    "\n",
    "    if \"folsom street\" in i:\n",
    "        for j in range(len(folsom_street)-1):\n",
    "            if traffic_information[j][j+1][1] != 0:\n",
    "                traffic_information[j][j+1][2] = 0.5\n",
    "        for j in range(len(folsom_street)-1, 0, -1):\n",
    "            if traffic_information[j][j-1][1] != 0:\n",
    "                traffic_information[j][j-1][2] = 0.5\n",
    "        print(\"updated folsom street\")\n",
    "\n",
    "    if \"main street\" in i:\n",
    "        for j in range(len(main_street)-1):\n",
    "            if traffic_information[j][j+1][1] != 0:\n",
    "                traffic_information[j][j+1][2] = 0.5\n",
    "        for j in range(len(main_street)-1, 0, -1):\n",
    "            if traffic_information[j][j-1][1] != 0:\n",
    "                traffic_information[j][j-1][2] = 0.5\n",
    "        print(\"updated main street\")\n",
    "\n",
    "    if \"spear street\" in i:\n",
    "        for j in range(len(spear_street)-1):\n",
    "            if traffic_information[j][j+1][1] != 0:\n",
    "                traffic_information[j][j+1][2] = 0.5\n",
    "        for j in range(len(spear_street)-1, 0, -1):\n",
    "            if traffic_information[j][j-1][1] != 0:\n",
    "                traffic_information[j][j-1][2] = 0.5\n",
    "        print(\"updated spear street\")\n",
    "\n",
    "    if \"beale street\" in i:\n",
    "        for j in range(len(beale_street)-1):\n",
    "            if traffic_information[j][j+1][1] != 0:\n",
    "                traffic_information[j][j+1][2] = 0.5\n",
    "        for j in range(len(beale_street)-1, 0, -1):\n",
    "            if traffic_information[j][j-1][1] != 0:\n",
    "                traffic_information[j][j-1][2] = 0.5\n",
    "        print(\"updated beale street\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:03:08.453021600Z",
     "start_time": "2024-04-25T17:03:08.433371500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated graph :  {'A': {'B': 140.0, 'E': 110.0}, 'B': {'A': 140.0, 'C': 130.0, 'F': 85.0}, 'C': {'B': 130.0, 'D': 135.0, 'G': 87.5}, 'D': {'C': 100.0, 'H': 110.0}, 'E': {'A': 115.0, 'F': 99999, 'I': 115.0}, 'F': {'B': 110.0, 'E': 75.0, 'G': 99999, 'J': 125.0}, 'G': {'C': 100.0, 'F': 78.33333333333333, 'H': 105.0, 'K': 72.5}, 'H': {'D': 95.0, 'G': 95.0, 'L': 95.0}, 'I': {'E': 120.0, 'J': 60.0}, 'J': {'F': 130.0, 'I': 99999, 'K': 70.0}, 'K': {'G': 80.0, 'J': 85.0, 'L': 70.0}, 'L': {'H': 95.0, 'K': 99999}}\n"
     ]
    }
   ],
   "source": [
    "# updating vehicle count based on the new information\n",
    "for i in traffic_information.keys():\n",
    "    for j in traffic_information[i].keys():\n",
    "        if traffic_information[i][j][0] != 0:\n",
    "            graph[i][j] = traffic_information[i][j][0] / traffic_information[i][j][1] * traffic_information[i][j][2]\n",
    "        else:\n",
    "            graph[i][j] = 99999\n",
    "print(\"updated graph : \", graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:07:15.530317500Z",
     "start_time": "2024-04-25T17:07:10.353929600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting point :  DATABRICKS\n",
      "ending point :  HYATT\n",
      "Latitude: 37.791099236856226, Longitude: -122.39393059431788\n",
      "Latitude: 37.79429458516023, Longitude: -122.3959216670412\n",
      "start, end : G, A\n",
      "Shortest Path: ['G', 'F', 'E', 'A']\n"
     ]
    }
   ],
   "source": [
    "start_place = input(\"Enter the start location : \").lower()\n",
    "end_place = input(\"Enter the end loaction : \").lower()\n",
    "print(\"starting point : \", start_place.upper())\n",
    "print(\"ending point : \", end_place.upper())\n",
    "\n",
    "# latitude_start, longitude_start = get_lat_long(start)\n",
    "latitude_start, longitude_start = get_building(start_place)\n",
    "if latitude_start is not None and longitude_start is not None:\n",
    "    print(f\"Latitude: {latitude_start}, Longitude: {longitude_start}\")\n",
    "else:\n",
    "    print(\"Failed to retrieve latitude and longitude.\")\n",
    "\n",
    "# latitude_end, longitude_end = get_lat_long(end)\n",
    "latitude_end, longitude_end = get_building(end_place)\n",
    "\n",
    "if latitude_end is not None and longitude_end is not None:\n",
    "    print(f\"Latitude: {latitude_end}, Longitude: {longitude_end}\")\n",
    "else:\n",
    "    print(\"Failed to retrieve latitude and longitude.\")\n",
    "\n",
    "start_coords = [latitude_start, longitude_start]\n",
    "end_coords = [latitude_end, longitude_end]\n",
    "\n",
    "start = distance(coordinates, latitude_start, longitude_start)\n",
    "end = distance(coordinates, latitude_end, longitude_end)\n",
    "print(\"start, end : {f1}, {f2}\".format(f1=start, f2=end))\n",
    "\n",
    "shortest_path = dijkstra(graph, start, end)\n",
    "if shortest_path:\n",
    "    print(\"Shortest Path:\", shortest_path)\n",
    "    # print(\"Total Cost:\", sum(graph[shortest_path[i]][shortest_path[i+1]] for i in range(len(shortest_path)-1)))\n",
    "else:\n",
    "    print(\"No path found!\")\n",
    "\n",
    "# Create a Folium map centered at the midpoint of the line\n",
    "map_center = [(start_coords[0] + end_coords[0]) / 2, (start_coords[1] + end_coords[1]) / 2]\n",
    "mymap = folium.Map(location=map_center, zoom_start=15)\n",
    "\n",
    "# Add a polyline connecting the start and end points\n",
    "for i in range(0,len(shortest_path)-1,1):\n",
    "    folium.PolyLine(locations=[coordinates[shortest_path[i]], coordinates[shortest_path[i+1]]], color='blue', weight=5).add_to(mymap)\n",
    "folium.PolyLine(locations=[start_coords, coordinates[start]], color='blue', weight=5).add_to(mymap)\n",
    "folium.PolyLine(locations=[end_coords, coordinates[end]], color='blue', weight=5).add_to(mymap)\n",
    "\n",
    "# Add markers for start and end points\n",
    "folium.Marker(location=start_coords, tooltip=start_place.upper()).add_to(mymap)\n",
    "folium.Marker(location=end_coords, tooltip=end_place.upper()).add_to(mymap)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "mymap.save(\"output.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
